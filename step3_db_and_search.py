# Cell 9
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_core.documents import Document
from langchain_community.retrievers import TavilySearchAPIRetriever
from langchain_core.tools import tool
from typing import List
import pandas as pd
import os


# ======================================================
# 1âƒ£ Google Gemini Embeddings ì´ˆê¸°í™” (ì„œë²„ í™˜ê²½ ëŒ€ì‘)
# ======================================================
# - Ollama ëŒ€ì‹  Google Gemini API ì‚¬ìš©
# - í•„ìš”: GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
# - ëª¨ë¸: text-embedding-004 (ìµœì‹  ì„ë² ë”© ëª¨ë¸)
print("Google Gemini Embeddings ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
embeddings_model = GoogleGenerativeAIEmbeddings(
    model="models/text-embedding-004",  # Gemini ì„ë² ë”© ëª¨ë¸
    task_type="retrieval_document"      # ë¬¸ì„œ ê²€ìƒ‰ ìµœì í™”
)


# ======================================================
# 2âƒ£ Chroma DB ìƒì„± ë˜ëŠ” ë¶ˆëŸ¬ì˜¤ê¸°
# ======================================================
persist_dir = "./chroma_guideline"
collection_name = "guideline_db"

if not os.path.exists(persist_dir):
    print(" ìµœì´ˆ ì‹¤í–‰: CSVì—ì„œ GuidelineDB ìƒì„± ì¤‘...")
    df = pd.read_csv("GuidelineDB.csv", encoding="utf-8")

    # CSVë¥¼ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    documents = []
    for _, row in df.iterrows():
        documents.append(
            Document(
                page_content=row["question"],
                metadata={
                    "answer": row["answer"],
                    "category": row.get("category", ""),
                    "source": "guidelineDB",
                    "source_name": "GuidelineDB",
                    "source_detail": row.get("ì¶œì²˜", "ì¶œì²˜ ë¯¸ê¸°ì¬"),
                }
            )
        )

    # í•œ ë²ˆì— DB ìƒì„± ë° ì €ì¥
    guideline_db = Chroma.from_documents(
        documents=documents,
        embedding=embeddings_model,
        collection_name=collection_name,
        persist_directory=persist_dir
    )
    print(" GuidelineDB ìƒì„± ì™„ë£Œ (Chroma persisted).")
else:
    print(" ê¸°ì¡´ GuidelineDB ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    guideline_db = Chroma(
        collection_name=collection_name,
        persist_directory=persist_dir,
        embedding_function=embeddings_model
    )
    print(" GuidelineDB ë¡œë“œ ì™„ë£Œ.")


# ======================================================
# 3âƒ£ Reranker ëª¨ë¸ ì„¤ì • (ìƒëµ - LangChain 1.0 í˜¸í™˜ì„± ë¬¸ì œë¡œ ì œê±°)
# ======================================================
# Reranker ê¸°ëŠ¥ì€ ê²€ìƒ‰ ê²°ê³¼ì˜ ìƒìœ„ Nê°œë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ê²ƒìœ¼ë¡œ ëŒ€ì²´
print(" Reranker ê¸°ëŠ¥ ìƒëµ (LangChain 1.0 í˜¸í™˜ì„±)")


# ======================================================
# 4âƒ£ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í•¨ìˆ˜ (í‚¤ì›Œë“œ + ë²¡í„°)
# ======================================================
def hybrid_search(query: str, k: int = 2) -> List[Document]:  #  ê¸°ë³¸ê°’ 2ê°œë¡œ ë³€ê²½
    """
    ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: í‚¤ì›Œë“œ ë§¤ì¹­ + ë²¡í„° ìœ ì‚¬ë„ + Reranker
    
    ë‹¨ê³„:
    1. í‚¤ì›Œë“œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
    2. í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œ í•„í„°ë§
    3. í•„í„°ë§ëœ ë¬¸ì„œì— ëŒ€í•´ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°
    4. Rerankerë¡œ ìµœì¢… ìˆœìœ„ ê²°ì •
    5. í‚¤ì›Œë“œ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
    """
    print(f"    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘...")
    
    # 1âƒ£ í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = [word for word in query.split() if len(word) >= 2]
    print(f"    ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
    
    # 2âƒ£ DBì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    collection = guideline_db._collection
    all_result = collection.get(include=['documents', 'metadatas'])
    all_contents = all_result.get('documents', [])
    all_metadatas = all_result.get('metadatas', [])
    
    # 3âƒ£ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
    keyword_matches = []
    for i, content in enumerate(all_contents):
        score = sum(1 for kw in keywords if kw.lower() in content.lower())
        
        if score > 0:
            keyword_matches.append({
                'content': content,
                'metadata': all_metadatas[i] if i < len(all_metadatas) else {},
                'score': score
            })
    
    print(f"    í‚¤ì›Œë“œ ë§¤ì¹­ ë¬¸ì„œ: {len(keyword_matches)}ê°œ")
    
    # 4âƒ£ í‚¤ì›Œë“œ ë§¤ì¹­ëœ ë¬¸ì„œ ì²˜ë¦¬
    if len(keyword_matches) > 0:
        # ì ìˆ˜ìˆœ ì •ë ¬ í›„ ìƒìœ„ 50ê°œ
        keyword_matches.sort(key=lambda x: x['score'], reverse=True)
        top_matches = keyword_matches[:min(50, len(keyword_matches))]
        
        # Document ê°ì²´ë¡œ ë³€í™˜
        candidate_docs = [
            Document(
                page_content=match['content'],
                metadata=match['metadata']
            )
            for match in top_matches
        ]
        
        # ìƒìœ„ kê°œ ì„ ì • (Reranker ì—†ì´)
        print(f"    ìƒìœ„ {k}ê°œ ì„ ì •...")
        return candidate_docs[:k]
    
    # 5âƒ£ í‚¤ì›Œë“œ ë§¤ì¹­ ì‹¤íŒ¨ â†’ ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰
    print(f"    í‚¤ì›Œë“œ ë§¤ì¹­ 0ê°œ, ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ í´ë°±")
    vector_results = guideline_db.similarity_search(query, k=k)
    return vector_results


# ======================================================
# 5âƒ£ GuidelineDB ê²€ìƒ‰ ë„êµ¬ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)
# ======================================================
@tool
def guideline_search(query: str) -> List[Document]:
    """
    GuidelineDBì—ì„œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    í‚¤ì›Œë“œ ë§¤ì¹­ + ë²¡í„° ìœ ì‚¬ë„ + Reranker ì¡°í•©
    """
    print(f"\n [GuidelineDB Hybrid Search] ì¿¼ë¦¬: {query}")
    
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰ (ìƒìœ„ 2ê°œë§Œ)
    docs = hybrid_search(query, k=2)  #  5ê°œ â†’ 2ê°œë¡œ ë³€ê²½
    
    if len(docs) == 0:
        print("â— ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return [Document(page_content="ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", metadata={"source": "guidelineDB"})]
    
    print(f"ğŸ“„ ìµœì¢… ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ")
    
    # ê²°ê³¼ í¬ë§·íŒ…
    formatted_docs = []
    for i, d in enumerate(docs, 1):
        q = d.page_content.strip()
        a = d.metadata.get("answer", "").strip()
        src_detail = d.metadata.get("source_detail", "ì¶œì²˜ ë¯¸ê¸°ì¬")
        
        print(f"   â–¶ [{i}] {q[:60]}... (ì¶œì²˜: {src_detail})")
        
        formatted_docs.append(
            Document(
                page_content=f"Q: {q}\nA: {a}",
                metadata={
                    "source": "guidelineDB",
                    "source_name": "GuidelineDB",
                    "source_detail": src_detail
                }
            )
        )
    
    print(" ê²€ìƒ‰ ì™„ë£Œ")
    return formatted_docs


# ======================================================
# 6âƒ£ ì›¹ ê²€ìƒ‰ ë„êµ¬
# ======================================================
print(" Tavily Web Search Retriever ì´ˆê¸°í™” ì¤‘...")
web_retriever = TavilySearchAPIRetriever(k=10)
print(" Web Retriever ì¤€ë¹„ ì™„ë£Œ.")


@tool
def web_search(query: str) -> List[Document]:
    """
    ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ëŠ” ì •ë³´ ë˜ëŠ” ìµœì‹  ì •ë³´ë¥¼ ì›¹ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    (ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ì œëª©, URL, ë‚´ìš© ìš”ì•½, ì¶œì²˜ë¥¼ í¬í•¨í•˜ì—¬ ë°˜í™˜)
    """
    print(f"\n [Web Search] ì¿¼ë¦¬ ì‹¤í–‰: {query}")
    # ê²€ìƒ‰ ì‹¤í–‰
    docs = web_retriever.invoke(query)
    
    # ìƒìœ„ 2ê°œ ë¬¸ì„œë§Œ ì„ ë³„ (Reranker ëŒ€ì‹ )
    if len(docs) > 2:
        docs = docs[:2]
    formatted_docs = []

    if len(docs) == 0:
        print("â— ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return [Document(page_content="ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", metadata={"source": "web search"})]

    print(f"ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")

    for i, doc in enumerate(docs):
        # ì•ˆì „í•˜ê²Œ URLê³¼ ì œëª© ì¶”ì¶œ
        source_url = doc.metadata.get("source", "URL ë¯¸ê¸°ì¬")
        title = doc.metadata.get("title", "ì œëª© ì—†ìŒ")
        snippet = doc.page_content[:400]

        print(f"   [{i+1}] {title}")
        print(f"       -> URL: {source_url}")

        formatted_docs.append(
            Document(
                page_content=(
                    f"ğŸ”¹ ì œëª©: {title}\n"
                    f"ğŸ”— ì¶œì²˜ URL: {source_url}\n"
                    f"ğŸ“„ ë‚´ìš© ìš”ì•½: {snippet}"
                ),
                metadata={
                    "source": "web search",
                    "source_name": title,
                    "source_url": source_url,
                    "source_detail": source_url
                }
            )
        )

    print(f" ì›¹ ê²€ìƒ‰ ê²°ê³¼ {len(formatted_docs)}ê°œ í¬ë§· ì™„ë£Œ.")
    return formatted_docs


# Cell 12
# ë„êµ¬ ëª©ë¡ì„ ì •ì˜ 
tools = [guideline_search, web_search]
